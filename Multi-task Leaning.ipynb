{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 116
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8108,
     "status": "ok",
     "timestamp": 1582965084445,
     "user": {
      "displayName": "Rohin Garg",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAn2DI9Fvm4QY6q8HS8NkUchCJTPc3yLcioW7GVvA=s64",
      "userId": "03455532354584450462"
     },
     "user_tz": -330
    },
    "id": "sKb4S7vqyepJ",
    "outputId": "2a0e401f-4f78-4523-aad5-aec2b0abf99e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/deepspeed.py:23: FutureWarning: transformers.deepspeed module is deprecated and will be removed in a future version. Please import deepspeed modules directly from transformers.integrations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['NLTK_DATA'] = 'nltk_data'\n",
    "\n",
    "import torch\n",
    "from transformers import *\n",
    "from transformers import BertForSequenceClassification, BertTokenizer\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "# import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import sentencepiece\n",
    "# from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== 实际使用的GPU设备 =====\n",
      "可见GPU数量: 1\n",
      "GPU 0: NVIDIA GeForce RTX 4090\n",
      "There is/are 1 GPU(s) available.\n",
      "We will use the GPU: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# 验证实际可见的GPU设备\n",
    "print(\"\\n===== 实际使用的GPU设备 =====\")\n",
    "print(f\"可见GPU数量: {torch.cuda.device_count()}\")\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    # device = torch.device(\"cuda\")\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print('There is/are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible. Somehow this isn't working!\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# 创建保存模型和预测的文件夹\n",
    "os.makedirs('./saved_preds', exist_ok=True)\n",
    "os.makedirs('./saved_models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义集成模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义本地模型路径\n",
    "LOCAL_MODEL_PATHS = {\n",
    "    'bert-large-uncased': 'bert-large-uncased',\n",
    "    'roberta-large': 'roberta-large',\n",
    "    'xlnet-large-cased': 'xlnet-large-cased'\n",
    "}\n",
    "\n",
    "# 启用多个模型配置\n",
    "MODELS = [\n",
    "    (BertForSequenceClassification, BertTokenizer, 'bert-large-uncased'),\n",
    "    (RobertaForSequenceClassification, RobertaTokenizer, 'roberta-large'),\n",
    "    (XLNetForSequenceClassification, XLNetTokenizer, 'xlnet-large-cased'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_corpus = pd.read_csv(\"subtask1_test.csv\", encoding='utf-8')\n",
    "master_corpus = pd.read_csv(\"subtask1_train_with_tense.csv\", encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file tokenizer.json\n",
      "loading configuration file bert-large-uncased/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file bert-large-uncased/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file bert-large-uncased/model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "=== Training Model: bert-large-uncased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2368/1912644093.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
      "/tmp/ipykernel_2368/1912644093.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.2924\n",
      "Main Task - Accuracy: 0.9266, Precision: 0.7732, Recall: 0.9075, F1: 0.8350\n",
      "Tense Task - Accuracy: 0.3683\n",
      "Epoch 2 - Loss: 0.1317\n",
      "Main Task - Accuracy: 0.9842, Precision: 0.9537, Recall: 0.9701, F1: 0.9618\n",
      "Tense Task - Accuracy: 0.5534\n",
      "Epoch 3 - Loss: 0.0919\n",
      "Main Task - Accuracy: 0.9929, Precision: 0.9802, Recall: 0.9852, F1: 0.9827\n",
      "Tense Task - Accuracy: 0.6212\n",
      "Epoch 4 - Loss: 0.0633\n",
      "Main Task - Accuracy: 0.9968, Precision: 0.9916, Recall: 0.9929, F1: 0.9923\n",
      "Tense Task - Accuracy: 0.6748\n",
      "Epoch 5 - Loss: 0.0421\n",
      "Main Task - Accuracy: 0.9984, Precision: 0.9960, Recall: 0.9963, F1: 0.9961\n",
      "Tense Task - Accuracy: 0.7144\n",
      "Epoch 6 - Loss: 0.0297\n",
      "Main Task - Accuracy: 0.9992, Precision: 0.9980, Recall: 0.9983, F1: 0.9981\n",
      "Tense Task - Accuracy: 0.7445\n",
      "Epoch 7 - Loss: 0.0222\n",
      "Main Task - Accuracy: 0.9993, Precision: 0.9980, Recall: 0.9987, F1: 0.9983\n",
      "Tense Task - Accuracy: 0.7686\n",
      "Epoch 8 - Loss: 0.0168\n",
      "Main Task - Accuracy: 0.9998, Precision: 0.9997, Recall: 0.9993, F1: 0.9995\n",
      "Tense Task - Accuracy: 0.7849\n",
      "Epoch 9 - Loss: 0.0135\n",
      "Main Task - Accuracy: 0.9997, Precision: 0.9990, Recall: 0.9993, F1: 0.9992\n",
      "Tense Task - Accuracy: 0.7980\n",
      "Epoch 10 - Loss: 0.0118\n",
      "Main Task - Accuracy: 0.9998, Precision: 0.9997, Recall: 0.9993, F1: 0.9995\n",
      "Tense Task - Accuracy: 0.8020\n",
      "\n",
      "Final Test Results:\n",
      "Main Task - Accuracy: 0.9714, Precision: 0.8685, Recall: 0.8591, F1: 0.8638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file tokenizer.json\n",
      "loading configuration file roberta-large/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file roberta-large/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file roberta-large/model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and predictions for bert-large-uncased\n",
      "\n",
      "\n",
      "=== Training Model: roberta-large ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-large and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2368/1912644093.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
      "/tmp/ipykernel_2368/1912644093.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.2548\n",
      "Main Task - Accuracy: 0.9357, Precision: 0.8060, Recall: 0.9031, F1: 0.8518\n",
      "Tense Task - Accuracy: 0.4273\n",
      "Epoch 2 - Loss: 0.1372\n",
      "Main Task - Accuracy: 0.9809, Precision: 0.9419, Recall: 0.9660, F1: 0.9538\n",
      "Tense Task - Accuracy: 0.5701\n",
      "Epoch 3 - Loss: 0.0975\n",
      "Main Task - Accuracy: 0.9904, Precision: 0.9717, Recall: 0.9818, F1: 0.9767\n",
      "Tense Task - Accuracy: 0.6184\n",
      "Epoch 4 - Loss: 0.0646\n",
      "Main Task - Accuracy: 0.9959, Precision: 0.9857, Recall: 0.9943, F1: 0.9899\n",
      "Tense Task - Accuracy: 0.6661\n",
      "Epoch 5 - Loss: 0.0502\n",
      "Main Task - Accuracy: 0.9981, Precision: 0.9936, Recall: 0.9970, F1: 0.9953\n",
      "Tense Task - Accuracy: 0.7057\n",
      "Epoch 6 - Loss: 0.0345\n",
      "Main Task - Accuracy: 0.9993, Precision: 0.9973, Recall: 0.9993, F1: 0.9983\n",
      "Tense Task - Accuracy: 0.7436\n",
      "Epoch 7 - Loss: 0.0253\n",
      "Main Task - Accuracy: 0.9994, Precision: 0.9976, Recall: 0.9993, F1: 0.9985\n",
      "Tense Task - Accuracy: 0.7660\n",
      "Epoch 8 - Loss: 0.0219\n",
      "Main Task - Accuracy: 0.9998, Precision: 0.9997, Recall: 0.9993, F1: 0.9995\n",
      "Tense Task - Accuracy: 0.7837\n",
      "Epoch 9 - Loss: 0.0155\n",
      "Main Task - Accuracy: 0.9995, Precision: 0.9983, Recall: 0.9993, F1: 0.9988\n",
      "Tense Task - Accuracy: 0.7956\n",
      "Epoch 10 - Loss: 0.0132\n",
      "Main Task - Accuracy: 0.9999, Precision: 0.9993, Recall: 1.0000, F1: 0.9997\n",
      "Tense Task - Accuracy: 0.8033\n",
      "\n",
      "Final Test Results:\n",
      "Main Task - Accuracy: 0.9789, Precision: 0.9202, Recall: 0.8753, F1: 0.8972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file spiece.model\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file tokenizer.json\n",
      "loading configuration file xlnet-large-cased/config.json\n",
      "Model config XLNetConfig {\n",
      "  \"_name_or_path\": \"xlnet-large-cased\",\n",
      "  \"architectures\": [\n",
      "    \"XLNetLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 4096,\n",
      "  \"d_model\": 1024,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mem_len\": null,\n",
      "  \"model_type\": \"xlnet\",\n",
      "  \"n_head\": 16,\n",
      "  \"n_layer\": 24,\n",
      "  \"pad_token_id\": 5,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 250\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"untie_r\": true,\n",
      "  \"use_mems_eval\": true,\n",
      "  \"use_mems_train\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading configuration file xlnet-large-cased/config.json\n",
      "Model config XLNetConfig {\n",
      "  \"architectures\": [\n",
      "    \"XLNetLMHeadModel\"\n",
      "  ],\n",
      "  \"attn_type\": \"bi\",\n",
      "  \"bi_data\": false,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"clamp_len\": -1,\n",
      "  \"d_head\": 64,\n",
      "  \"d_inner\": 4096,\n",
      "  \"d_model\": 1024,\n",
      "  \"dropout\": 0.1,\n",
      "  \"end_n_top\": 5,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ff_activation\": \"gelu\",\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mem_len\": null,\n",
      "  \"model_type\": \"xlnet\",\n",
      "  \"n_head\": 16,\n",
      "  \"n_layer\": 24,\n",
      "  \"pad_token_id\": 5,\n",
      "  \"reuse_len\": null,\n",
      "  \"same_length\": false,\n",
      "  \"start_n_top\": 5,\n",
      "  \"summary_activation\": \"tanh\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"last\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 250\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"untie_r\": true,\n",
      "  \"use_mems_eval\": true,\n",
      "  \"use_mems_train\": false,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file xlnet-large-cased/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model and predictions for roberta-large\n",
      "\n",
      "\n",
      "=== Training Model: xlnet-large-cased ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-large-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-large-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_2368/1912644093.py:21: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
      "/tmp/ipykernel_2368/1912644093.py:30: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
      "/root/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Loss: 0.2983\n",
      "Main Task - Accuracy: 0.9162, Precision: 0.7527, Recall: 0.8795, F1: 0.8112\n",
      "Tense Task - Accuracy: 0.4056\n",
      "Epoch 2 - Loss: 0.1495\n",
      "Main Task - Accuracy: 0.9773, Precision: 0.9395, Recall: 0.9502, F1: 0.9448\n",
      "Tense Task - Accuracy: 0.5588\n",
      "Epoch 3 - Loss: 0.0935\n",
      "Main Task - Accuracy: 0.9908, Precision: 0.9702, Recall: 0.9855, F1: 0.9778\n",
      "Tense Task - Accuracy: 0.6246\n",
      "Epoch 4 - Loss: 0.0635\n",
      "Main Task - Accuracy: 0.9957, Precision: 0.9869, Recall: 0.9923, F1: 0.9896\n",
      "Tense Task - Accuracy: 0.6806\n",
      "Epoch 5 - Loss: 0.0458\n",
      "Main Task - Accuracy: 0.9981, Precision: 0.9940, Recall: 0.9966, F1: 0.9953\n",
      "Tense Task - Accuracy: 0.7241\n",
      "Epoch 6 - Loss: 0.0318\n",
      "Main Task - Accuracy: 0.9992, Precision: 0.9973, Recall: 0.9990, F1: 0.9982\n",
      "Tense Task - Accuracy: 0.7549\n",
      "Epoch 7 - Loss: 0.0215\n",
      "Main Task - Accuracy: 0.9992, Precision: 0.9976, Recall: 0.9987, F1: 0.9982\n",
      "Tense Task - Accuracy: 0.7814\n",
      "Epoch 8 - Loss: 0.0166\n",
      "Main Task - Accuracy: 0.9997, Precision: 0.9997, Recall: 0.9987, F1: 0.9992\n",
      "Tense Task - Accuracy: 0.8008\n",
      "Epoch 9 - Loss: 0.0109\n",
      "Main Task - Accuracy: 0.9996, Precision: 0.9987, Recall: 0.9993, F1: 0.9990\n",
      "Tense Task - Accuracy: 0.8167\n",
      "Epoch 10 - Loss: 0.0094\n",
      "Main Task - Accuracy: 0.9997, Precision: 0.9990, Recall: 0.9993, F1: 0.9992\n",
      "Tense Task - Accuracy: 0.8228\n",
      "\n",
      "Final Test Results:\n",
      "Main Task - Accuracy: 0.9777, Precision: 0.9110, Recall: 0.8740, F1: 0.8921\n",
      "Saved model and predictions for xlnet-large-cased\n"
     ]
    }
   ],
   "source": [
    "# Multi-Task Learning\n",
    "\n",
    "# 首先，创建一个多任务的数据集类\n",
    "class MultiTaskClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, corpus, train_corpus, tokenizer, max_len=128, is_test=False):\n",
    "        self.corpus = corpus\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # 计算主任务的类别权重\n",
    "        label_counts = train_corpus['gold_label'].value_counts()\n",
    "        total = len(train_corpus)\n",
    "        self.main_task_weights = torch.tensor([total / label_counts[i] for i in range(len(label_counts))], dtype=torch.float32).to(device)\n",
    "        \n",
    "        # 只在训练集上计算辅助任务的权重\n",
    "        if not is_test and 'tense' in corpus.columns:\n",
    "            # 计算辅助任务（时态）的类别权重\n",
    "            tense_counts = train_corpus['tense'].value_counts()\n",
    "            self.num_tenses = len(tense_counts)\n",
    "            self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
    "            \n",
    "            # 创建时态到索引的映射\n",
    "            self.tense_to_idx = {tense: idx for idx, tense in enumerate(sorted(train_corpus['tense'].unique()))}\n",
    "        else:\n",
    "            # 对于测试集，我们需要从训练集获取时态信息\n",
    "            if 'tense' in train_corpus.columns:\n",
    "                tense_counts = train_corpus['tense'].value_counts()\n",
    "                self.num_tenses = len(tense_counts)\n",
    "                self.tense_weights = torch.tensor([total / tense_counts[i] for i in range(len(tense_counts))], dtype=torch.float32).to(device)\n",
    "                self.tense_to_idx = {tense: idx for idx, tense in enumerate(sorted(train_corpus['tense'].unique()))}\n",
    "            else:\n",
    "                self.num_tenses = 0\n",
    "                self.tense_weights = None\n",
    "                self.tense_to_idx = {}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.corpus.iloc[idx]\n",
    "        text = row['sentence']\n",
    "        main_label = row['gold_label']\n",
    "        \n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        result = {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'main_label': torch.tensor(main_label, dtype=torch.long),\n",
    "        }\n",
    "        \n",
    "        # 只在训练时添加时态标签\n",
    "        if not self.is_test and 'tense' in row.index:\n",
    "            tense_label = self.tense_to_idx[row['tense']]\n",
    "            result['tense_label'] = torch.tensor(tense_label, dtype=torch.long)\n",
    "        else:\n",
    "            # 对于测试集，使用一个占位符\n",
    "            result['tense_label'] = torch.tensor(0, dtype=torch.long)\n",
    "            \n",
    "        return result\n",
    "\n",
    "# 创建一个多任务模型包装器\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, base_model, num_main_labels=2, num_tense_labels=None):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.base_model = base_model\n",
    "        self.num_main_labels = num_main_labels\n",
    "        self.num_tense_labels = num_tense_labels\n",
    "        \n",
    "        # 获取隐藏层大小\n",
    "        hidden_size = base_model.config.hidden_size\n",
    "        \n",
    "        # 主任务分类头\n",
    "        self.main_classifier = nn.Linear(hidden_size, num_main_labels)\n",
    "        \n",
    "        # 辅助任务（时态）分类头\n",
    "        self.tense_classifier = nn.Linear(hidden_size, num_tense_labels)\n",
    "        \n",
    "        # Dropout层\n",
    "        dropout = getattr(base_model.config, 'hidden_dropout_prob', None)\n",
    "        if dropout is None:\n",
    "            dropout = getattr(base_model.config, 'dropout', 0.1)  # XLNet 使用的是 'dropout'\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 确定基础模型的类型\n",
    "        self.model_type = base_model.config.model_type\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        # 根据模型类型使用不同的方法获取表示\n",
    "        if self.model_type == 'bert':\n",
    "            # BERT模型\n",
    "            outputs = self.base_model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            pooled_output = outputs.pooler_output\n",
    "            \n",
    "        elif self.model_type == 'roberta':\n",
    "            # RoBERTa 没有 pooler_output，使用 [CLS] token 的表示\n",
    "            outputs = self.base_model.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            sequence_output = outputs.last_hidden_state\n",
    "            pooled_output = sequence_output[:, 0]  # 取第一个 token ([CLS])\n",
    "            \n",
    "        elif self.model_type == 'xlnet':\n",
    "            # XLNet模型\n",
    "            outputs = self.base_model.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            # XLNet没有pooler_output，使用最后一个token的表示\n",
    "            # 对于XLNet，最后一个token通常是最好的句子表示\n",
    "            sequence_output = outputs.last_hidden_state\n",
    "            # 获取每个序列的最后一个有效token\n",
    "            if attention_mask is not None:\n",
    "                # 找到每个序列的最后一个非padding位置\n",
    "                seq_lengths = attention_mask.sum(dim=1) - 1\n",
    "                batch_size = input_ids.size(0)\n",
    "                pooled_output = sequence_output[range(batch_size), seq_lengths]\n",
    "            else:\n",
    "                # 如果没有attention_mask，使用最后一个位置\n",
    "                pooled_output = sequence_output[:, -1]\n",
    "                \n",
    "        else:\n",
    "            # 其他模型的通用处理\n",
    "            outputs = self.base_model(\n",
    "                input_ids=input_ids, \n",
    "                attention_mask=attention_mask,\n",
    "                output_hidden_states=True,\n",
    "                return_dict=True\n",
    "            )\n",
    "            \n",
    "            if hasattr(outputs, 'pooler_output') and outputs.pooler_output is not None:\n",
    "                pooled_output = outputs.pooler_output\n",
    "            else:\n",
    "                # 使用[CLS] token（第一个token）\n",
    "                last_hidden_state = outputs.hidden_states[-1]\n",
    "                pooled_output = last_hidden_state[:, 0]\n",
    "        \n",
    "        # 应用dropout\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        \n",
    "        # 主任务输出\n",
    "        main_logits = self.main_classifier(pooled_output)\n",
    "        \n",
    "        # 辅助任务输出\n",
    "        tense_logits = self.tense_classifier(pooled_output)\n",
    "        \n",
    "        return {\n",
    "            'main_logits': main_logits,\n",
    "            'tense_logits': tense_logits\n",
    "        }\n",
    "\n",
    "\n",
    "# 主训练循环\n",
    "for model_class, tokenizer_class, pretrained_weights in MODELS:\n",
    "    print(f\"\\n\\n=== Training Model: {pretrained_weights} ===\\n\")\n",
    "    \n",
    "    # Loading the data\n",
    "    train_corpus, test_corpus = master_corpus, test_corpus\n",
    "    \n",
    "    # 从本地加载预训练模型\n",
    "    local_path = LOCAL_MODEL_PATHS[pretrained_weights]\n",
    "    tokenizer = tokenizer_class.from_pretrained(local_path)\n",
    "    base_model = model_class.from_pretrained(\n",
    "        local_path,\n",
    "        num_labels=2,\n",
    "        output_hidden_states=False,\n",
    "        output_attentions=False\n",
    "    )\n",
    "    \n",
    "    # 创建多任务数据集\n",
    "    train_dataset = MultiTaskClassificationDataset(train_corpus, train_corpus, tokenizer, max_len=128, is_test=False)\n",
    "    test_dataset = MultiTaskClassificationDataset(test_corpus, train_corpus, tokenizer, max_len=128, is_test=True)\n",
    "    \n",
    "    # 创建多任务模型\n",
    "    model = MultiTaskModel(base_model, num_main_labels=2, num_tense_labels=train_dataset.num_tenses)\n",
    "    model.to(device)\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    def collate_fn(batch):\n",
    "        input_ids = torch.stack([item['input_ids'] for item in batch])\n",
    "        attention_mask = torch.stack([item['attention_mask'] for item in batch])\n",
    "        main_labels = torch.stack([item['main_label'] for item in batch])\n",
    "        tense_labels = torch.stack([item['tense_label'] for item in batch])\n",
    "        return input_ids, attention_mask, main_labels, tense_labels\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
    "    \n",
    "    # 定义损失函数\n",
    "    main_criterion = nn.CrossEntropyLoss(weight=train_dataset.main_task_weights)\n",
    "    tense_criterion = nn.CrossEntropyLoss(weight=train_dataset.tense_weights)\n",
    "    \n",
    "    # 定义多任务损失权重（可以调整）\n",
    "    main_task_weight = 0.7\n",
    "    tense_task_weight = 0.3\n",
    "    \n",
    "    epochs = 10\n",
    "    \n",
    "    # 优化器\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "    \n",
    "    # 学习率调度器\n",
    "    total_train_steps = len(train_loader) * epochs\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=total_train_steps\n",
    "    )\n",
    "    \n",
    "    # 训练循环\n",
    "    for epoch in range(epochs):   \n",
    "        model.train()\n",
    "        \n",
    "        train_main_preds = []\n",
    "        train_main_labels = []\n",
    "        train_tense_preds = []\n",
    "        train_tense_labels = []\n",
    "        total_loss = 0\n",
    "        \n",
    "        for i, (input_ids, attention_mask, main_labels, tense_labels) in enumerate(train_loader):\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            main_labels = main_labels.to(device)\n",
    "            tense_labels = tense_labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            \n",
    "            # 计算多任务损失\n",
    "            main_loss = main_criterion(outputs['main_logits'], main_labels)\n",
    "            tense_loss = tense_criterion(outputs['tense_logits'], tense_labels)\n",
    "            \n",
    "            # 组合损失\n",
    "            loss = main_task_weight * main_loss + tense_task_weight * tense_loss\n",
    "            \n",
    "            # 反向传播\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            # 记录预测结果\n",
    "            main_preds = torch.argmax(outputs['main_logits'], dim=1).cpu().numpy()\n",
    "            tense_preds = torch.argmax(outputs['tense_logits'], dim=1).cpu().numpy()\n",
    "            \n",
    "            train_main_preds.extend(main_preds)\n",
    "            train_main_labels.extend(main_labels.cpu().numpy())\n",
    "            train_tense_preds.extend(tense_preds)\n",
    "            train_tense_labels.extend(tense_labels.cpu().numpy())\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        # 计算主任务指标\n",
    "        main_acc = accuracy_score(train_main_labels, train_main_preds)\n",
    "        main_prec = precision_score(train_main_labels, train_main_preds)\n",
    "        main_rec = recall_score(train_main_labels, train_main_preds)\n",
    "        main_f1 = f1_score(train_main_labels, train_main_preds)\n",
    "        \n",
    "        # 计算辅助任务指标\n",
    "        tense_acc = accuracy_score(train_tense_labels, train_tense_preds)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} - Loss: {total_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Main Task - Accuracy: {main_acc:.4f}, Precision: {main_prec:.4f}, Recall: {main_rec:.4f}, F1: {main_f1:.4f}\")\n",
    "        print(f\"Tense Task - Accuracy: {tense_acc:.4f}\")\n",
    "    \n",
    "    # 测试阶段 - 只关注主任务\n",
    "    model.eval()\n",
    "    test_main_preds = []\n",
    "    test_main_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for input_ids, attention_mask, main_labels, _ in test_loader:  # 忽略时态标签\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            main_labels = main_labels.to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            \n",
    "            # 只获取主任务的预测\n",
    "            main_preds = torch.argmax(outputs['main_logits'], dim=1).cpu().numpy()\n",
    "            \n",
    "            test_main_preds.extend(main_preds)\n",
    "            test_main_labels.extend(main_labels.cpu().numpy())\n",
    "    \n",
    "    # 计算测试集指标 - 只计算主任务\n",
    "    main_acc = accuracy_score(test_main_labels, test_main_preds)\n",
    "    main_prec = precision_score(test_main_labels, test_main_preds)\n",
    "    main_rec = recall_score(test_main_labels, test_main_preds)\n",
    "    main_f1 = f1_score(test_main_labels, test_main_preds)\n",
    "    \n",
    "    print(f\"\\nFinal Test Results:\")\n",
    "    print(f\"Main Task - Accuracy: {main_acc:.4f}, Precision: {main_prec:.4f}, Recall: {main_rec:.4f}, F1: {main_f1:.4f}\")\n",
    "    \n",
    "    # 保存模型和预测结果\n",
    "    model_name = pretrained_weights.replace(\"-\", \"_\")\n",
    "    torch.save(model.state_dict(), f'./saved_models/{model_name}_multitask.pt')\n",
    "    np.save(f'./saved_preds/{model_name}_main_preds.npy', test_main_preds)\n",
    "    print(f\"Saved model and predictions for {pretrained_weights}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for BERT Large: 0.8685\n",
      "Recall for BERT Large: 0.8591\n",
      "F1 Score for BERT Large: 0.8638\n",
      "\n",
      "Precision for RoBERTa Large: 0.9202\n",
      "Recall for RoBERTa Large: 0.8753\n",
      "F1 Score for RoBERTa Large: 0.8972\n",
      "\n",
      "Precision for XLNet Large: 0.9110\n",
      "Recall for XLNet Large: 0.8740\n",
      "F1 Score for XLNet Large: 0.8921\n",
      "\n",
      "Precision for Ensemble Model: 0.9130\n",
      "Recall for Ensemble Model: 0.8821\n",
      "F1_ensemble Score on Test Set: 0.8973\n"
     ]
    }
   ],
   "source": [
    "# Multi-Task\n",
    "\n",
    "# 加载所有模型的预测结果\n",
    "bert_large = np.load(\"saved_preds/bert_large_uncased_main_preds.npy\")\n",
    "roberta_large = np.load(\"saved_preds/roberta_large_main_preds.npy\")\n",
    "xlnet_large = np.load(\"saved_preds/xlnet_large_cased_main_preds.npy\")\n",
    "\n",
    "# 投票集成\n",
    "final_pred = bert_large + roberta_large + xlnet_large\n",
    "preds = (final_pred >= 2).astype(int)  # 至少两个模型认为是反事实才预测为 1\n",
    "\n",
    "# 打印F1\n",
    "# 加载测试集的标签\n",
    "test_labels = pd.read_csv(\"subtask1_test.csv\")[\"gold_label\"].values\n",
    "\n",
    "bert_precision = precision_score(test_labels, bert_large)\n",
    "bert_recall = recall_score(test_labels, bert_large)\n",
    "bert_f1 = f1_score(test_labels, bert_large)\n",
    "\n",
    "roberta_precision = precision_score(test_labels, roberta_large)\n",
    "roberta_recall = recall_score(test_labels, roberta_large)\n",
    "roberta_f1 = f1_score(test_labels, roberta_large)\n",
    "\n",
    "xlnet_precision = precision_score(test_labels, xlnet_large)\n",
    "xlnet_recall = recall_score(test_labels, xlnet_large)\n",
    "xlnet_f1 = f1_score(test_labels, xlnet_large)\n",
    "\n",
    "# 计算最终模型 F1 分数\n",
    "f1_ensemble = f1_score(test_labels, preds)\n",
    "precision_ensemble = precision_score(test_labels, preds)\n",
    "recall_ensemble = recall_score(test_labels, preds)\n",
    "\n",
    "# 打印每个模型的 F1 分数\n",
    "\n",
    "print(f\"Precision for BERT Large: {bert_precision:.4f}\")\n",
    "print(f\"Recall for BERT Large: {bert_recall:.4f}\")\n",
    "print(f\"F1 Score for BERT Large: {bert_f1:.4f}\\n\")\n",
    "\n",
    "print(f\"Precision for RoBERTa Large: {roberta_precision:.4f}\")\n",
    "print(f\"Recall for RoBERTa Large: {roberta_recall:.4f}\")\n",
    "print(f\"F1 Score for RoBERTa Large: {roberta_f1:.4f}\\n\")\n",
    "\n",
    "print(f\"Precision for XLNet Large: {xlnet_precision:.4f}\")\n",
    "print(f\"Recall for XLNet Large: {xlnet_recall:.4f}\")\n",
    "print(f\"F1 Score for XLNet Large: {xlnet_f1:.4f}\\n\")\n",
    "\n",
    "print(f\"Precision for Ensemble Model: {precision_ensemble:.4f}\")\n",
    "print(f\"Recall for Ensemble Model: {recall_ensemble:.4f}\")\n",
    "print(f\"F1_ensemble Score on Test Set: {f1_ensemble:.4f}\")\n",
    "\n",
    "# 保存最终集成结果\n",
    "# np.save(\"final_ensemble_preds.npy\", preds)\n",
    "# print(\"✅ 集成预测完成，结果已保存至 final_ensemble_preds.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 在原来代码的基础上，加上第四个模型：Roberta_large+语言学特征（结合nltk）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Roberta_large+语言学特征（结合nltk）\"\"\"\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "\n",
    "nltk.data.path.append(\"nltk_data\")\n",
    "punkt_path = \"nltk_data/tokenizers/punkt\" \n",
    "nltk.data.path.append(punkt_path)\n",
    "averaged_perceptron_tagger_path = \"nltk_data/taggers/averaged_perceptron_tagger\"\n",
    "nltk.data.path.append(averaged_perceptron_tagger_path)\n",
    "punkt_tab_path = \"nltk_data/tokenizers/punkt_tab\"\n",
    "nltk.data.path.append(punkt_tab_path)\n",
    "punkt_tab_english_path = \"nltk_data/tokenizers/punkt_tab/english\"\n",
    "nltk.data.path.append(punkt_tab_english_path)\n",
    "averaged_perceptron_tagger_eng_path = \"nltk_data/taggers/averaged_perceptron_tagger_eng\"\n",
    "nltk.data.path.append(averaged_perceptron_tagger_eng_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义本地模型路径\n",
    "LOCAL_MODEL_PATHS = {\n",
    "    # 'roberta-large': '/mnt/disk2/xiaolin.zhang/nlp_finalproject/iitk/huggingface/hub/models--roberta-large/snapshots/722cf37b1afa9454edce342e7895e588b6ff1d59',\n",
    "    'roberta-large': 'roberta-large',\n",
    "}\n",
    "\n",
    "# 启用多个模型配置\n",
    "MODELS = [\n",
    "    (RobertaModel, RobertaTokenizer, 'roberta-large'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.json\n",
      "loading file merges.txt\n",
      "loading file added_tokens.json\n",
      "loading file special_tokens_map.json\n",
      "loading file tokenizer_config.json\n",
      "loading file tokenizer.json\n",
      "loading configuration file roberta-large/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-large\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading configuration file roberta-large/config.json\n",
      "Model config RobertaConfig {\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file roberta-large/model.safetensors\n",
      "Some weights of the model checkpoint at roberta-large were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(max_features=1000, ngram_range=(3, 3))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(max_features=1000, ngram_range=(3, 3))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(max_features=1000, ngram_range=(3, 3))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载预训练模型和 Tokenizer\n",
    "model_class, tokenizer_class, pretrained_weights = (RobertaModel, RobertaTokenizer, 'roberta-large')\n",
    "tokenizer = tokenizer_class.from_pretrained(LOCAL_MODEL_PATHS[pretrained_weights])\n",
    "base_model = model_class.from_pretrained(LOCAL_MODEL_PATHS[pretrained_weights], output_hidden_states=False, output_attentions=False).to(device)\n",
    "\n",
    "# 数据读取\n",
    "train_corpus = pd.read_csv(\"subtask1_train_with_tense.csv\", encoding='utf-8')\n",
    "test_corpus = pd.read_csv(\"subtask1_test.csv\", encoding='utf-8')\n",
    "\n",
    "# 提取 POS 和 N-gram 特征\n",
    "def extract_pos_tags(sent):\n",
    "    return \" \".join([pairs[1] for pairs in pos_tag(word_tokenize(sent))])\n",
    "\n",
    "train_corpus['pos_string'] = train_corpus['sentence'].apply(extract_pos_tags)\n",
    "test_corpus['pos_string'] = test_corpus['sentence'].apply(extract_pos_tags)\n",
    "\n",
    "pos_vectorizer = CountVectorizer(ngram_range=(3, 3), max_features=1000)\n",
    "pos_vectorizer.fit(train_corpus['pos_string'])\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(ngram_range=(3, 3), max_features=1000)\n",
    "ngram_vectorizer.fit(train_corpus['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Train Loss: 0.6931\n",
      "Main Task - Train Acc: 0.9306, Prec: 0.9204, Recall: 0.7238, F1: 0.8103\n",
      "Test - Main Task Acc: 0.9721, Prec: 0.8694, Recall: 0.8659, F1: 0.8676\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2 - Train Loss: 0.4258\n",
      "Main Task - Train Acc: 0.9742, Prec: 0.9548, Recall: 0.9176, F1: 0.9358\n",
      "Test - Main Task Acc: 0.9726, Prec: 0.8945, Recall: 0.8388, F1: 0.8657\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3 - Train Loss: 0.3267\n",
      "Main Task - Train Acc: 0.9818, Prec: 0.9656, Recall: 0.9448, F1: 0.9551\n",
      "Test - Main Task Acc: 0.9736, Prec: 0.9196, Recall: 0.8211, F1: 0.8676\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4 - Train Loss: 0.2631\n",
      "Main Task - Train Acc: 0.9897, Prec: 0.9816, Recall: 0.9680, F1: 0.9748\n",
      "Test - Main Task Acc: 0.9737, Prec: 0.9086, Recall: 0.8347, F1: 0.8701\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5 - Train Loss: 0.2189\n",
      "Main Task - Train Acc: 0.9925, Prec: 0.9851, Recall: 0.9781, F1: 0.9816\n",
      "Test - Main Task Acc: 0.9743, Prec: 0.9227, Recall: 0.8252, F1: 0.8712\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6 - Train Loss: 0.1797\n",
      "Main Task - Train Acc: 0.9948, Prec: 0.9905, Recall: 0.9842, F1: 0.9873\n",
      "Test - Main Task Acc: 0.9747, Prec: 0.8705, Recall: 0.8930, F1: 0.8816\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7 - Train Loss: 0.1480\n",
      "Main Task - Train Acc: 0.9971, Prec: 0.9946, Recall: 0.9913, F1: 0.9929\n",
      "Test - Main Task Acc: 0.9747, Prec: 0.9036, Recall: 0.8509, F1: 0.8765\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8 - Train Loss: 0.1255\n",
      "Main Task - Train Acc: 0.9969, Prec: 0.9933, Recall: 0.9916, F1: 0.9924\n",
      "Test - Main Task Acc: 0.9749, Prec: 0.9145, Recall: 0.8401, F1: 0.8757\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9 - Train Loss: 0.1087\n",
      "Main Task - Train Acc: 0.9977, Prec: 0.9949, Recall: 0.9936, F1: 0.9943\n",
      "Test - Main Task Acc: 0.9756, Prec: 0.8965, Recall: 0.8686, F1: 0.8823\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10 - Train Loss: 0.0964\n",
      "Main Task - Train Acc: 0.9981, Prec: 0.9963, Recall: 0.9943, F1: 0.9953\n",
      "Test - Main Task Acc: 0.9751, Prec: 0.9196, Recall: 0.8374, F1: 0.8766\n",
      "--------------------------------------------------------------------------------\n",
      "Model and predictions saved!\n"
     ]
    }
   ],
   "source": [
    "# 自定义 Dataset\n",
    "class MultiTaskClassificationDataset(Dataset):\n",
    "    def __init__(self, corpus, train_corpus, tokenizer, pos_vectorizer, ngram_vectorizer, max_len=128, is_test=False):\n",
    "        self.corpus = corpus.reset_index()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.pos_vectorizer = pos_vectorizer\n",
    "        self.ngram_vectorizer = ngram_vectorizer\n",
    "        self.is_test = is_test\n",
    "        \n",
    "        # Tokenize sentences\n",
    "        self.encodings = [\n",
    "            self.tokenizer.encode(sent, add_special_tokens=True, max_length=self.max_len, truncation=True, padding='max_length')\n",
    "            for sent in self.corpus['sentence']\n",
    "        ]\n",
    "        \n",
    "        # Convert to tensors\n",
    "        self.encodings = [torch.tensor(seq, dtype=torch.long) for seq in self.encodings]\n",
    "        self.labels = self.corpus['gold_label'].values\n",
    "        \n",
    "        # 处理时态标签\n",
    "        if not is_test and 'tense' in corpus.columns:\n",
    "            # 创建时态到索引的映射\n",
    "            self.tense_to_idx = {tense: idx for idx, tense in enumerate(sorted(train_corpus['tense'].unique()))}\n",
    "            self.num_tenses = len(self.tense_to_idx)\n",
    "            self.tense_labels = [self.tense_to_idx[tense] for tense in self.corpus['tense']]\n",
    "        else:\n",
    "            # 对于测试集，使用训练集的时态映射\n",
    "            if 'tense' in train_corpus.columns:\n",
    "                self.tense_to_idx = {tense: idx for idx, tense in enumerate(sorted(train_corpus['tense'].unique()))}\n",
    "                self.num_tenses = len(self.tense_to_idx)\n",
    "            else:\n",
    "                self.tense_to_idx = {}\n",
    "                self.num_tenses = 0\n",
    "            # 测试集使用占位符\n",
    "            self.tense_labels = [0] * len(self.corpus)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.encodings[idx].to(device)\n",
    "        label = torch.tensor(self.labels[idx]).to(device)\n",
    "        tense_label = torch.tensor(self.tense_labels[idx]).to(device)\n",
    "        \n",
    "        sentence = self.corpus.iloc[idx]['sentence']\n",
    "        pos_feat = self.pos_vectorizer.transform([self.corpus.iloc[idx]['pos_string']]).toarray().squeeze().astype(np.float32)\n",
    "        ngram_feat = self.ngram_vectorizer.transform([sentence]).toarray().squeeze().astype(np.float32)\n",
    "        \n",
    "        pos_tensor = torch.from_numpy(pos_feat).to(device)\n",
    "        ngram_tensor = torch.from_numpy(ngram_feat).to(device)\n",
    "        \n",
    "        return input_ids, label, tense_label, pos_tensor, ngram_tensor\n",
    "\n",
    "# 定义多任务模型\n",
    "class MultiTaskCustomModel(nn.Module):\n",
    "    def __init__(self, base_model, num_tenses):\n",
    "        super(MultiTaskCustomModel, self).__init__()\n",
    "        self.transformer = base_model\n",
    "        \n",
    "        # 共享特征提取层\n",
    "        self.lin1 = nn.Linear(1024 + 1000 + 1000, 512)\n",
    "        self.lin2 = nn.Linear(512, 64)\n",
    "        \n",
    "        # 主任务分类头\n",
    "        self.main_classifier = nn.Linear(64, 2)\n",
    "        \n",
    "        # 辅助任务（时态）分类头\n",
    "        self.tense_classifier = nn.Linear(64, num_tenses)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_ids, pos_feats, ngram_feats):\n",
    "        outputs = self.transformer(input_ids)\n",
    "        pooled_output = outputs[1]  # Shape: (batch_size, hidden_size)\n",
    "        \n",
    "        # 结合所有特征\n",
    "        combined = torch.cat((pooled_output, pos_feats, ngram_feats), dim=-1)\n",
    "        \n",
    "        # 共享特征提取\n",
    "        x = F.relu(self.lin1(combined))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # 主任务输出\n",
    "        main_logits = self.main_classifier(x)\n",
    "        \n",
    "        # 辅助任务输出\n",
    "        tense_logits = self.tense_classifier(x)\n",
    "        \n",
    "        return main_logits, tense_logits\n",
    "\n",
    "# 初始化 Dataset 和 DataLoader\n",
    "train_dataset = MultiTaskClassificationDataset(train_corpus, train_corpus, tokenizer, pos_vectorizer, ngram_vectorizer, max_len=128, is_test=False)\n",
    "test_dataset = MultiTaskClassificationDataset(test_corpus, train_corpus, tokenizer, pos_vectorizer, ngram_vectorizer, max_len=128, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "# 实例化多任务模型\n",
    "model = MultiTaskCustomModel(base_model, num_tenses=train_dataset.num_tenses).to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "main_criterion = nn.CrossEntropyLoss()\n",
    "tense_criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 多任务损失权重\n",
    "main_task_weight = 0.7\n",
    "tense_task_weight = 0.3\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5, eps=1e-8)\n",
    "\n",
    "total_train_steps = len(train_loader) * 10\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_train_steps)\n",
    "\n",
    "# 训练循环\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    train_main_preds, train_main_labels = [], []\n",
    "    train_tense_preds, train_tense_labels = [], []\n",
    "    \n",
    "    for i, data in enumerate(train_loader):\n",
    "        input_ids, main_labels, tense_labels, pos_feats, ngram_feats = data\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 前向传播\n",
    "        main_outputs, tense_outputs = model(input_ids, pos_feats, ngram_feats)\n",
    "        \n",
    "        # 计算多任务损失\n",
    "        main_loss = main_criterion(main_outputs, main_labels)\n",
    "        tense_loss = tense_criterion(tense_outputs, tense_labels)\n",
    "        \n",
    "        # 组合损失\n",
    "        loss = main_task_weight * main_loss + tense_task_weight * tense_loss\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        # 梯度裁剪\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # 记录预测结果\n",
    "        main_preds = torch.argmax(main_outputs, dim=1).cpu().numpy()\n",
    "        tense_preds = torch.argmax(tense_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        train_main_preds.extend(main_preds)\n",
    "        train_main_labels.extend(main_labels.cpu().numpy())\n",
    "        train_tense_preds.extend(tense_preds)\n",
    "        train_tense_labels.extend(tense_labels.cpu().numpy())\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} - Train Loss: {total_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    # 主任务指标\n",
    "    print(f\"Main Task - Train Acc: {accuracy_score(train_main_labels, train_main_preds):.4f}, \"\n",
    "          f\"Prec: {precision_score(train_main_labels, train_main_preds):.4f}, \"\n",
    "          f\"Recall: {recall_score(train_main_labels, train_main_preds):.4f}, \"\n",
    "          f\"F1: {f1_score(train_main_labels, train_main_preds):.4f}\")\n",
    "    \n",
    "    # 辅助任务指标（只在训练时显示）\n",
    "    if not test_dataset.is_test:\n",
    "        print(f\"Tense Task - Train Acc: {accuracy_score(train_tense_labels, train_tense_preds):.4f}\")\n",
    "\n",
    "    # 测试阶段 - 只关注主任务\n",
    "    model.eval()\n",
    "    test_main_preds, test_main_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            input_ids, main_labels, _, pos_feats, ngram_feats = data  # 忽略时态标签\n",
    "            main_outputs, _ = model(input_ids, pos_feats, ngram_feats)  # 忽略时态输出\n",
    "            \n",
    "            preds = torch.argmax(main_outputs, dim=1).cpu().numpy()\n",
    "            test_main_preds.extend(preds)\n",
    "            test_main_labels.extend(main_labels.cpu().numpy())\n",
    "\n",
    "    print(f\"Test - Main Task Acc: {accuracy_score(test_main_labels, test_main_preds):.4f}, \"\n",
    "          f\"Prec: {precision_score(test_main_labels, test_main_preds):.4f}, \"\n",
    "          f\"Recall: {recall_score(test_main_labels, test_main_preds):.4f}, \"\n",
    "          f\"F1: {f1_score(test_main_labels, test_main_preds):.4f}\")\n",
    "    print(\"-\" * 80)\n",
    "\n",
    "# 保存模型和预测结果\n",
    "torch.save(model.state_dict(), \"./saved_models/roberta_large_pos_ngram_multitask.pth\")\n",
    "np.save(\"./saved_preds/roberta_large_pos_ngram_multitask.npy\", test_main_preds)\n",
    "print(\"Model and predictions saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for RoBERTa Large + nltk: 0.9148\n",
      "Recall for RoBERTa Large + nltk: 0.8875\n",
      "F1 Score for RoBERTa Large + nltk: 0.9010\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 加载所有模型的预测结果\n",
    "roberta_large_pos_ngram = np.load(\"saved_preds/roberta_large_pos_ngram.npy\")\n",
    "\n",
    "test_labels = pd.read_csv(\"subtask1_test.csv\")[\"gold_label\"].values\n",
    "\n",
    "# 打印F1\n",
    "# 加载测试集的标签\n",
    "\n",
    "roberta_large_pos_ngram_precision = precision_score(test_labels, roberta_large_pos_ngram)\n",
    "roberta_large_pos_ngram_recall = recall_score(test_labels, roberta_large_pos_ngram)\n",
    "roberta_large_pos_ngram_f1 = f1_score(test_labels, roberta_large_pos_ngram)\n",
    "\n",
    "print(f\"Precision for RoBERTa Large + nltk: {roberta_large_pos_ngram_precision:.4f}\")\n",
    "print(f\"Recall for RoBERTa Large + nltk: {roberta_large_pos_ngram_recall:.4f}\")\n",
    "print(f\"F1 Score for RoBERTa Large + nltk: {roberta_large_pos_ngram_f1:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision for Ensemble Model: 0.9024\n",
      "Recall for Ensemble Model: 0.9024\n",
      "F1_ensemble Score on Test Set: 0.9024\n"
     ]
    }
   ],
   "source": [
    "# 加载所有模型的预测结果\n",
    "bert_large = np.load(\"saved_preds/bert_large_uncased_main_preds.npy\")\n",
    "roberta_large = np.load(\"saved_preds/roberta_large_main_preds.npy\")\n",
    "xlnet_large = np.load(\"saved_preds/xlnet_large_cased_main_preds.npy\")\n",
    "\n",
    "# 投票集成\n",
    "final_pred = bert_large + roberta_large + xlnet_large + roberta_large_pos_ngram\n",
    "preds = (final_pred >= 2).astype(int)  # 至少两个模型认为是反事实才预测为 1\n",
    "\n",
    "# 计算最终模型 F1 分数\n",
    "f1_ensemble = f1_score(test_labels, preds)\n",
    "precision_ensemble = precision_score(test_labels, preds)\n",
    "recall_ensemble = recall_score(test_labels, preds)\n",
    "\n",
    "# 打印每个模型的 F1 分数\n",
    "print(f\"Precision for Ensemble Model: {precision_ensemble:.4f}\")\n",
    "print(f\"Recall for Ensemble Model: {recall_ensemble:.4f}\")\n",
    "print(f\"F1_ensemble Score on Test Set: {f1_ensemble:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "voting of 3 transformer_baseline.ipynb",
   "provenance": [
    {
     "file_id": "1DTbYI_bgQljngtN9b09S2znGaqUsDvu1",
     "timestamp": 1582825796897
    },
    {
     "file_id": "1WlpZOxP3YgwllqKn2H3rcBJuhGe6H2u3",
     "timestamp": 1582823073870
    },
    {
     "file_id": "1vWlKxVBu82x73C4ZI0aqsl8gXi0OTpsW",
     "timestamp": 1582730282048
    }
   ]
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09c632c1b0884b9797c4b3887a6fd456": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b9747e0a3494736a2bc512470bf9aa6",
      "placeholder": "​",
      "style": "IPY_MODEL_222057aca2134f2a8fb97cfba1762b08",
      "value": "100% 362/362 [00:00&lt;00:00, 13.5kB/s]"
     }
    },
    "12bf5fb0b8c64eabbaf65fe81075a378": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d23a6d4541f145eeb6807c4d4b4691af",
      "placeholder": "​",
      "style": "IPY_MODEL_845a78a9c4af4c12882d24086b8184a9",
      "value": "100% 232k/232k [00:00&lt;00:00, 427kB/s]"
     }
    },
    "222057aca2134f2a8fb97cfba1762b08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2334f62b75f1418fad7e4ba376bc0e72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "271dbf24b1c844c8a791f5ad8a998a6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5aa489639bb24075a68a4f8520e34601",
      "placeholder": "​",
      "style": "IPY_MODEL_afba953fb4f84423be40d5d895b63cfe",
      "value": "100% 1.34G/1.34G [01:55&lt;00:00, 11.6MB/s]"
     }
    },
    "57329d636a8c4699a70a361068e0391f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5aa489639bb24075a68a4f8520e34601": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b9747e0a3494736a2bc512470bf9aa6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ba56cd2cdfb4bf4882345509cef87c2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d90c483577cf46f1ab346803de5300ed",
       "IPY_MODEL_09c632c1b0884b9797c4b3887a6fd456"
      ],
      "layout": "IPY_MODEL_a73534fb52994a349cc63484f33f819c"
     }
    },
    "8263a27d38a349928eb0c45dcf3e55e6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "845a78a9c4af4c12882d24086b8184a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8bc9af57a8cd4f97b179aeb765aaf99b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "8f9cde4c46234c38b16bea53f17cb6fa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9d424363671349578a04fd8246639f94": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bd2dae251daf4e1a9d9ab4c4bbc41d25",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57329d636a8c4699a70a361068e0391f",
      "value": 231508
     }
    },
    "a73534fb52994a349cc63484f33f819c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "afba953fb4f84423be40d5d895b63cfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b5ecca696f1e4bf89284de2a43926c1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f22370b8f1134359b123f9f06ab330b7",
       "IPY_MODEL_271dbf24b1c844c8a791f5ad8a998a6c"
      ],
      "layout": "IPY_MODEL_8f9cde4c46234c38b16bea53f17cb6fa"
     }
    },
    "bd2dae251daf4e1a9d9ab4c4bbc41d25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d23a6d4541f145eeb6807c4d4b4691af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d826582003704642a244f9e5fb5e41ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9d424363671349578a04fd8246639f94",
       "IPY_MODEL_12bf5fb0b8c64eabbaf65fe81075a378"
      ],
      "layout": "IPY_MODEL_ecc691742ac946ebbe542a517ea38cbe"
     }
    },
    "d90c483577cf46f1ab346803de5300ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2334f62b75f1418fad7e4ba376bc0e72",
      "max": 362,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8bc9af57a8cd4f97b179aeb765aaf99b",
      "value": 362
     }
    },
    "ecc691742ac946ebbe542a517ea38cbe": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f22370b8f1134359b123f9f06ab330b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f24871c5b7f74ec0a930b764fe954229",
      "max": 1344997306,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8263a27d38a349928eb0c45dcf3e55e6",
      "value": 1344997306
     }
    },
    "f24871c5b7f74ec0a930b764fe954229": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
